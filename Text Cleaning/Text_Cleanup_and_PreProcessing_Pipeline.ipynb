{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Cleanup and PreProcessing Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_XPSlwaplAI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP_o6-IQpKQ6",
        "outputId": "cd5ab8e5-9e3b-4fff-93ae-12b633f63e40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfkQXpUBpcv3"
      },
      "source": [
        "df_en = pd.read_csv('/content/drive/MyDrive/Thesis/final_en_data.csv')\n",
        "df_bn = pd.read_csv('/content/drive/MyDrive/Thesis/final_bn_data.csv')\n",
        "df_bn = df_bn.drop(['category'],axis=1)\n",
        "\n",
        "df_bn.label = df_bn.label.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNBgnu0Qs5an",
        "outputId": "c93d9c90-f657-4f82-c61d-429879f986d3"
      },
      "source": [
        "df_en.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "headline    0\n",
              "content     0\n",
              "label       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LKvL0rJ0R8A"
      },
      "source": [
        "df_en= df_en.rename({'headline': 'title', 'content': 'text','label': 'target'}, axis=1)\n",
        "df_bn= df_bn.rename({'headline': 'title', 'content': 'text','label': 'target'}, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxEzojW526TQ"
      },
      "source": [
        "df_en['text'] = df_en['title'] +'. ' + df_en['text']\n",
        "df_bn['text'] = df_bn['title'] +'। ' + df_bn['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MWtlWDN-0LpQ",
        "outputId": "2a4270ed-3de6-4f6e-d84a-45b3b60544d2"
      },
      "source": [
        "df_en.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Invoking religion, a more disciplined Trump sp...</td>\n",
              "      <td>Invoking religion, a more disciplined Trump sp...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Top Trump lieutenant Scaramucci lashes colleag...</td>\n",
              "      <td>Top Trump lieutenant Scaramucci lashes colleag...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let Us Now Praise Famous Trumps</td>\n",
              "      <td>Let Us Now Praise Famous Trumps. November 7, 2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U.S. seeks ship ban over North Korea violation...</td>\n",
              "      <td>U.S. seeks ship ban over North Korea violation...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Links 11/3/16</td>\n",
              "      <td>Links 11/3/16. November 3, 2016 at 7:14 am \\nH...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ... target\n",
              "0  Invoking religion, a more disciplined Trump sp...  ...      1\n",
              "1  Top Trump lieutenant Scaramucci lashes colleag...  ...      1\n",
              "2                    Let Us Now Praise Famous Trumps  ...      0\n",
              "3  U.S. seeks ship ban over North Korea violation...  ...      1\n",
              "4                                      Links 11/3/16  ...      0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g53OXDdpfpN",
        "outputId": "299d2ea9-3a3a-47b9-d2ef-14849e4084e6"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re \n",
        "import nltk\n",
        "\n",
        "nltk.download(\"stopwords\")   \n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "lemma = nltk.WordNetLemmatizer()\n",
        "\n",
        "# function to remove HTML tags\n",
        "def remove_html_tags(text):\n",
        "    return BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "\n",
        "# function to remove accented characters\n",
        "import unicodedata\n",
        "def remove_accented_chars(text):\n",
        "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return new_text\n",
        "\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# function to remove special characters\n",
        "def remove_special_characters(text):\n",
        "    # define the pattern to keep\n",
        "    pat = r'[^a-zA-z0-9,!?/:;\\\"\\'\\s]' \n",
        "    return re.sub(pat, '', text)\n",
        " \n",
        "import string\n",
        "# function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    text = ''.join([c for c in text if c not in string.punctuation])\n",
        "    return text\n",
        "\n",
        "\n",
        "# function to remove special characters\n",
        "def remove_extra_whitespace_tabs(text):\n",
        "    #pattern = r'^\\s+$|\\s+$'\n",
        "    pattern = r'^\\s*|\\s\\s*'\n",
        "    return re.sub(pattern, ' ', text).strip()\n",
        "\n",
        "\"\"\"\n",
        "# function for stemming\n",
        "def get_stem(text):\n",
        "    stemmer = nltk.porter.PorterStemmer()\n",
        "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
        "    return text\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# function to remove special characters\n",
        "def lower(text):\n",
        "    \n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Removal of stopwords \n",
        "def remove_stopwords_and_lemmatization(text):\n",
        "    final_text = []\n",
        "    text = text.lower()\n",
        "    text = nltk.word_tokenize(text)\n",
        "    \n",
        "    for word in text:\n",
        "        if word not in set(stopwords.words('english')):\n",
        "            lemma = nltk.WordNetLemmatizer()\n",
        "            word = lemma.lemmatize(word) \n",
        "            final_text.append(word)\n",
        "    return \" \".join(final_text)\n",
        "\n",
        "#Total function\n",
        "def cleaning(text):\n",
        "    text = remove_html_tags(text)\n",
        "    text = decontracted(text)    \n",
        "    text = remove_accented_chars(text)\n",
        "    text = remove_special_characters(text)\n",
        "    text = remove_punctuation(text)\n",
        "    text = remove_extra_whitespace_tabs(text)\n",
        "    text = lower(text)\n",
        "    #text = remove_stopwords_and_lemmatization(text)\n",
        "    return text\n",
        "\n",
        "#Apply function on text column\n",
        "\n",
        "df_en['text']=df_en['text'].apply(cleaning)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCNjR8O5yCGC",
        "outputId": "facf4224-08a2-4111-89a4-822fef744660"
      },
      "source": [
        "df_en.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65076, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O5sWsfEyJUE",
        "outputId": "1dbd621f-09a0-48c5-d5aa-bdd818631b7a"
      },
      "source": [
        "df_en.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title     0\n",
              "text      0\n",
              "target    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ulgKq_KxjPD",
        "outputId": "d4c89d38-2d27-41e3-9a9e-a7aecd65a661"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lQaddTjxlcK",
        "outputId": "6f041ed0-e864-4c94-c082-0c8c8ba89511"
      },
      "source": [
        "cd drive/MyDrive/Thesis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Thesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3w3zon6xqmC",
        "outputId": "3f6e78f6-3ff7-4a06-ab34-a3327521706b"
      },
      "source": [
        "from google.colab import  drive\n",
        "\n",
        "drive.mount('/drive')\n",
        "df_en.to_csv('/drive/My Drive/Thesis/without_stop_lemma_clean_english.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "lT6YytrHx591",
        "outputId": "3ae3d5d2-77a3-40e3-a2bf-02f43823d0bf"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "clean_english = pd.read_csv('/content/drive/MyDrive/Thesis/without_stop_lemma_clean_english.csv')\n",
        "clean_english.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Invoking religion, a more disciplined Trump sp...</td>\n",
              "      <td>invoking religion a more disciplined trump spe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Top Trump lieutenant Scaramucci lashes colleag...</td>\n",
              "      <td>top trump lieutenant scaramucci lashes colleag...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let Us Now Praise Famous Trumps</td>\n",
              "      <td>let us now praise famous trumps november 7 201...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U.S. seeks ship ban over North Korea violation...</td>\n",
              "      <td>us seeks ship ban over north korea violations ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Links 11/3/16</td>\n",
              "      <td>links 11316 november 3 2016 at 714 am hostilit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  ... target\n",
              "0  Invoking religion, a more disciplined Trump sp...  ...      1\n",
              "1  Top Trump lieutenant Scaramucci lashes colleag...  ...      1\n",
              "2                    Let Us Now Praise Famous Trumps  ...      0\n",
              "3  U.S. seeks ship ban over North Korea violation...  ...      1\n",
              "4                                      Links 11/3/16  ...      0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "vf2dTRG5ChTi",
        "outputId": "a830f8f2-baac-414c-a7dd-e5e8d42f78b8"
      },
      "source": [
        "df_bn.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>৮ দিনে ১৮ বিল পাস!</td>\n",
              "      <td>৮ দিনে ১৮ বিল পাস!। দশম জাতীয় সংসদের মেয়াদ শেষ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আ’লীগের জনসভায় লোকে লোকারণ্য ফেনী ট্রাংক রোড</td>\n",
              "      <td>আ’লীগের জনসভায় লোকে লোকারণ্য ফেনী ট্রাংক রোড। ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>মাদ্রাসায় জোড়া খুন: পরিচালক তিন দিনের রিমান্ডে</td>\n",
              "      <td>মাদ্রাসায় জোড়া খুন: পরিচালক তিন দিনের রিমান্ডে...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>নেপালকে হারিয়ে গ্রুপ চ্যাম্পিয়ন বাংলাদেশ</td>\n",
              "      <td>নেপালকে হারিয়ে গ্রুপ চ্যাম্পিয়ন বাংলাদেশ। সাফ ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>কুড়িগ্রামে ২ শিক্ষার্থীর লাশ উদ্ধার</td>\n",
              "      <td>কুড়িগ্রামে ২ শিক্ষার্থীর লাশ উদ্ধার। কুড়িগ্রাম...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            title  ... target\n",
              "0                              ৮ দিনে ১৮ বিল পাস!  ...      0\n",
              "1    আ’লীগের জনসভায় লোকে লোকারণ্য ফেনী ট্রাংক রোড  ...      0\n",
              "2  মাদ্রাসায় জোড়া খুন: পরিচালক তিন দিনের রিমান্ডে  ...      0\n",
              "3        নেপালকে হারিয়ে গ্রুপ চ্যাম্পিয়ন বাংলাদেশ  ...      1\n",
              "4             কুড়িগ্রামে ২ শিক্ষার্থীর লাশ উদ্ধার  ...      1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zfMFyTW0qLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9926ea2f-8bf3-462c-e8d7-c0283f516922"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re \n",
        "\n",
        "from bnlp.corpus import stopwords, punctuations, letters, digits\n",
        "from bnlp.corpus import stopwords\n",
        "from bnlp.corpus.util import remove_stopwords\n",
        "\n",
        "#from bnltk.stemmer import BanglaStemmer\n",
        "\n",
        "import banglanltk as bn\n",
        "\n",
        "# function to remove HTML tags\n",
        "def remove_html_tags(text):\n",
        "    return BeautifulSoup(text, 'html.parser').get_text()\n",
        "\n",
        "\n",
        " \n",
        "import string\n",
        "# function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    text = ''.join([c for c in text if c not in string.punctuation])\n",
        "    return text\n",
        "\n",
        "\n",
        "# function to remove special characters\n",
        "def remove_extra_whitespace_tabs(text):\n",
        "    #pattern = r'^\\s+$|\\s+$'\n",
        "    pattern = r'^\\s*|\\s\\s*'\n",
        "    return re.sub(pattern, ' ', text).strip()\n",
        "\n",
        "def remove_bn_stopwords(text):\n",
        "    final_text = []\n",
        "    text = remove_stopwords(text, stopwords)\n",
        "        \n",
        "    for word in text:\n",
        "      text = remove_stopwords(word, stopwords)\n",
        "      final_text.append(word)\n",
        "    return \" \".join(final_text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def bn_lemmatization(text):\n",
        "\n",
        "    #text1 = bn.stemmer(text)\n",
        "    return bn.stemmer(text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Total function\n",
        "def cleaning(text):\n",
        "    text = remove_html_tags(text)\n",
        "  \n",
        "    #text = remove_bn_stopwords(text)\n",
        "    \n",
        "    text = remove_punctuation(text)\n",
        "    text = remove_extra_whitespace_tabs(text)\n",
        "    #text = bn_lemmatization(text)\n",
        "  \n",
        "    return text\n",
        "\n",
        "#Apply function on text column\n",
        "\n",
        "df_bn['text']=df_bn['text'].apply(cleaning)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punkt not found. downloading...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rclJtPNo4kOQ",
        "outputId": "e8cb0000-0be8-4791-8fcb-58f91650719a"
      },
      "source": [
        "df_bn.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14537, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wUvgW8c4n0V",
        "outputId": "a8567011-51f3-473b-d34b-8f10dfb0484b"
      },
      "source": [
        "df_bn.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title     0\n",
              "text      0\n",
              "target    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5YMx9gZ4zHu",
        "outputId": "342d699a-fad2-4d16-b917-a11b9e97039c"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXN-djsc4YlA",
        "outputId": "7907ffdd-8747-4032-93c1-fa680e0d4cf9"
      },
      "source": [
        "from google.colab import  drive\n",
        "\n",
        "drive.mount('/drive')\n",
        "df_bn.to_csv('/drive/My Drive/Thesis/withoutstopstm_clean_bengali.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "p-8iYNly45le",
        "outputId": "398a7fd4-b967-4028-cd93-02e0934116d5"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "clean_bengali = pd.read_csv('/content/drive/MyDrive/Thesis/withoutstopstm_clean_bengali.csv')\n",
        "clean_bengali.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>৮ দিনে ১৮ বিল পাস!</td>\n",
              "      <td>৮ দিনে ১৮ বিল পাস। দশম জাতীয় সংসদের মেয়াদ শেষ ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আ’লীগের জনসভায় লোকে লোকারণ্য ফেনী ট্রাংক রোড</td>\n",
              "      <td>আ’লীগের জনসভায় লোকে লোকারণ্য ফেনী ট্রাংক রোড। ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>মাদ্রাসায় জোড়া খুন: পরিচালক তিন দিনের রিমান্ডে</td>\n",
              "      <td>মাদ্রাসায় জোড়া খুন পরিচালক তিন দিনের রিমান্ডে।...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>নেপালকে হারিয়ে গ্রুপ চ্যাম্পিয়ন বাংলাদেশ</td>\n",
              "      <td>নেপালকে হারিয়ে গ্রুপ চ্যাম্পিয়ন বাংলাদেশ। সাফ ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>কুড়িগ্রামে ২ শিক্ষার্থীর লাশ উদ্ধার</td>\n",
              "      <td>কুড়িগ্রামে ২ শিক্ষার্থীর লাশ উদ্ধার। কুড়িগ্রাম...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            title  ... target\n",
              "0                              ৮ দিনে ১৮ বিল পাস!  ...      0\n",
              "1    আ’লীগের জনসভায় লোকে লোকারণ্য ফেনী ট্রাংক রোড  ...      0\n",
              "2  মাদ্রাসায় জোড়া খুন: পরিচালক তিন দিনের রিমান্ডে  ...      0\n",
              "3        নেপালকে হারিয়ে গ্রুপ চ্যাম্পিয়ন বাংলাদেশ  ...      1\n",
              "4             কুড়িগ্রামে ২ শিক্ষার্থীর লাশ উদ্ধার  ...      1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ-Jt_u_HCyO",
        "outputId": "69a195ef-ce62-41f6-8d11-1e09d1befa96"
      },
      "source": [
        "!pip install bnlp_toolkit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bnlp_toolkit\n",
            "  Downloading bnlp_toolkit-3.1.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.4.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.19.5)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (0.8.2)\n",
            "Collecting gensim==4.0.1\n",
            "  Downloading gensim-4.0.1-cp37-cp37m-manylinux1_x86_64.whl (23.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9 MB 74.5 MB/s \n",
            "\u001b[?25hCollecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.1->bnlp_toolkit) (5.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->bnlp_toolkit) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (4.62.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.8.9)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 60.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, sentencepiece, gensim, bnlp-toolkit\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed bnlp-toolkit-3.1.1 gensim-4.0.1 python-crfsuite-0.9.7 sentencepiece-0.1.96 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6bYasRoJGij",
        "outputId": "67e11053-9f1f-4250-fd7a-238e5a234f32"
      },
      "source": [
        "pip install banglanltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting banglanltk\n",
            "  Downloading banglanltk-0.0.4-py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: banglanltk\n",
            "Successfully installed banglanltk-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-UGXvazRV_O",
        "outputId": "5db502ff-e553-42f6-8bc9-511a0afa42db"
      },
      "source": [
        "import banglanltk as bn\n",
        "\n",
        "# For single word\n",
        "print(bn.stemmer('ছাত্রীকে'))\n",
        "\n",
        "# For multiple words\n",
        "text = 'আজ বৃষ্টি হবে।'\n",
        "words = bn.word_tokenize(text)\n",
        "for w in words:\n",
        "    print(bn.stemmer(w))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ছাত্রী\n",
            "আজ\n",
            "বৃষ্টি\n",
            "হব\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}